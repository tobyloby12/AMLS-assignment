{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model and using feature extraction to find different features and reduce curse of dimensionality\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hog_features(image):\n",
    "    hog_image = cv2.resize(image, (512, 256), interpolation=cv2.INTER_AREA)\n",
    "    fd, hog_image = hog(hog_image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "    return fd, hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
    "\n",
    "def lbp_feature_selection(image):\n",
    "    lbp = local_binary_pattern(image, 24, 3, )\n",
    "    \n",
    "\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, 24 + 3), range=(0, 24 + 2))\n",
    "    # normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    # return the histogram of Local Binary Patterns\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 2100/2100 [08:54<00:00,  3.93it/s]"
     ]
    }
   ],
   "source": [
    "# loading in images and turing it into an array to use as features, collecting labels\n",
    "path = os.getcwd()\n",
    "\n",
    "path = os.path.join(path, 'dataset')\n",
    "df_labels = pd.read_csv(os.path.join(path, 'label.csv'))\n",
    "\n",
    "# getting train and test dataframes\n",
    "train = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "\n",
    "classes = {'meningioma_tumor': 0, 'no_tumor': 1, 'glioma_tumor': 2, 'pituitary_tumor': 3}\n",
    "\n",
    "def feature_extraction(dataset, img_path, name):\n",
    "    features = []\n",
    "    hog_features = []\n",
    "    lbp_features = []\n",
    "    labels = []\n",
    "    for row in tqdm(dataset.iterrows(), total=dataset.shape[0], desc=\"Progress\"):\n",
    "        image_name = row[1][0]\n",
    "        label = row[1][1]\n",
    "        # opening and flattening image\n",
    "        img = cv2.imread(os.path.join(img_path, image_name))\n",
    "        # images are gray scale so there is useless data using RGB\n",
    "        grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # calculating hog features\n",
    "        fd, hog_image = calculate_hog_features(grayscale)\n",
    "        fd = []\n",
    "        # calculating LBP\n",
    "        lbp_hist = lbp_feature_selection(grayscale)\n",
    "        \n",
    "        hog_features.append(fd)\n",
    "        lbp_features.append(lbp_features)\n",
    "\n",
    "        features.append(np.concatenate((fd, lbp_hist)))\n",
    "        labels.append(classes.get(label))\n",
    "    # saving features for use later\n",
    "    np.save(f'./features/{name}/hog_features.npy', hog_features)\n",
    "    np.save(f'./features/{name}/lbp_features.npy', lbp_features)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "train_path = os.path.join(path, 'train')\n",
    "test_path = os.path.join(path, 'test')\n",
    "\n",
    "x_train, y_train = feature_extraction(train, train_path, 'train')\n",
    "x_test, y_test = feature_extraction(test, test_path, 'test')\n",
    "\n",
    "print('Train size: ', len(x_train))\n",
    "print('Test size: ', len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA fitting for dimensionality reduction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def dimensionality_reduction(x_train, x_test):\n",
    "    scalar = StandardScaler()\n",
    "\n",
    "    # scaling data to perform pca on it\n",
    "    scalar.fit(x_train)\n",
    "\n",
    "    # applying scale to xtrain and xtest\n",
    "    x_train = scalar.transform(x_train)\n",
    "    x_test = scalar.transform(x_test)\n",
    "\n",
    "\n",
    "    # creating pca\n",
    "    pca = PCA(.95)\n",
    "\n",
    "    # fitting pca on training data\n",
    "    pca.fit(x_train)\n",
    "\n",
    "    # applying to train and test\n",
    "    x_train = pca.transform(x_train)\n",
    "    x_test = pca.transform(x_test)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = dimensionality_reduction(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 1055)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_random_forest = RandomForestClassifier()\n",
    "\n",
    "model_random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "# getting accuracy metrics and printing\n",
    "pred = model_random_forest.predict(x_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print('accuracy: ', score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad58f19c577ffc0aca1ae55e125c232e81de10d1e77d9589b8201c7b12408e24"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('amls-assignment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
